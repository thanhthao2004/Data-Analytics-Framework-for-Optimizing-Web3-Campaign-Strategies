# analysis/pillar2_gas_model.py (KH·ªöP V·ªöI S∆† ƒê·ªí)
import pandas as pd
import numpy as np
from connectors.db_connector import BigQueryConnector
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
import warnings

class GasCostForecaster:
    """
    Tri·ªÉn khai Tr·ª• c·ªôt 2: M√¥ h√¨nh Kinh t·∫ø Gas.
    Kh·ªõp v·ªõi s∆° ƒë·ªì Mermaid P2.
    
    M√¥ h√¨nh D·ª± b√°o: ARIMA(1, 1, 1)
    ===============================
    
    ƒê·ªô tin c·∫≠y v√† Gi·ªõi h·∫°n:
    ----------------------
    - M√¥ h√¨nh ARIMA(1, 1, 1) ph√π h·ª£p ƒë·ªÉ n·∫Øm b·∫Øt xu h∆∞·ªõng v√† t√≠nh m√πa v·ª• NG·∫ÆN H·∫†N 
      (d∆∞·ªõi 7 ng√†y) c·ªßa Base Fee tr√™n Ethereum.
    - ƒê·ªô ch√≠nh x√°c s·∫Ω GI·∫¢M NHANH khi k√©o d√†i d·ª± b√°o qu√° 7 ng√†y do:
      * Base Fee tr√™n Ethereum bi·∫øn ƒë·ªông ph·ª• thu·ªôc v√†o nhi·ªÅu y·∫øu t·ªë ph·ª©c t·∫°p
      * ARIMA l√† m√¥ h√¨nh tuy·∫øn t√≠nh, c√≥ th·ªÉ b·ªè l·ª° c√°c m·ªëi quan h·ªá phi tuy·∫øn
    
    ƒê·ªô nh·∫°y v√† C·∫£nh b√°o:
    --------------------
    - M√¥ h√¨nh R·∫§T NH·∫†Y C·∫¢M v·ªõi c√°c s·ª± ki·ªán kh√¥ng l∆∞·ªùng tr∆∞·ªõc (Black Swan events):
      * N√¢ng c·∫•p m·∫°ng (EIP-1559, Merge, c√°c hard fork kh√°c)
      * S·ª± ki·ªán mint NFT l·ªõn (v√≠ d·ª•: c√°c d·ª± √°n NFT h√†ng ƒë·∫ßu ph√°t h√†nh)
      * TƒÉng ƒë·ªôt bi·∫øn ph√≠ giao d·ªãch do c√° voi thao t√∫ng ho·∫∑c flash crash
      * C√°c s·ª± ki·ªán DeFi l·ªõn (liquidations h√†ng lo·∫°t, bridge hacks)
    - C·∫ßn c√≥ c∆° ch·∫ø c·∫£nh b√°o ho·∫∑c fallback cho nh·ªØng tr∆∞·ªùng h·ª£p n√†y.
    - D·ªØ li·ªáu l·ªãch s·ª≠ ch·ªâ d√πng 30 ng√†y g·∫ßn nh·∫•t ƒë·ªÉ c√¢n b·∫±ng gi·ªØa ƒë·ªô m·ªõi v√† chi ph√≠ truy v·∫•n.
    
    Khuy·∫øn ngh·ªã S·ª≠ d·ª•ng:
    -------------------
    - S·ª≠ d·ª•ng d·ª± b√°o cho c·ª≠a s·ªï 4 gi·ªù (rolling average) ƒë·ªÉ gi·∫£m nhi·ªÖu.
    - K·∫øt h·ª£p v·ªõi c√°c ngu·ªìn d·ªØ li·ªáu kh√°c (GasNow, Etherscan forecasters) ƒë·ªÉ x√°c nh·∫≠n.
    - Kh√¥ng n√™n ch·ªâ d·ª±a v√†o m√¥ h√¨nh n√†y cho c√°c quy·∫øt ƒë·ªãnh quan tr·ªçng v·ªÅ chi ph√≠.
    """
    def __init__(self, db: BigQueryConnector):
        self.db = db
        self.model_fit = None

    def _fetch_hourly_gas(self, days_back=30):
        """
        L·∫•y d·ªØ li·ªáu base_fee trung b√¨nh h√†ng gi·ªù t·ª´ BigQuery.
        Kh·ªõp v·ªõi lu·ªìng: _fetch_hourly_gas() -> Run BigQuery SQL
        """
        print(f"[Pillar 2] ƒêang l·∫•y d·ªØ li·ªáu gas l·ªãch s·ª≠ ({days_back} ng√†y)...")
        
        # Truy v·∫•n n√†y kh·ªõp v·ªõi m√¥ t·∫£ trong s∆° ƒë·ªì
        query = f"""
            SELECT
                TIMESTAMP_TRUNC(timestamp, HOUR) AS hour,
                AVG(base_fee_per_gas) / 1e9 AS avg_gwei -- ƒê·ªïi sang Gwei
            FROM `bigquery-public-data.crypto_ethereum.blocks`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days_back} DAY)
            GROUP BY 1
            ORDER BY 1
        """
        df = self.db.query_to_dataframe(query)
        if df.empty:
            print("[Pillar 2] Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu gas.")
            return None
            
        df['hour'] = pd.to_datetime(df['hour'], utc=True)
        df.set_index('hour', inplace=True)
        
        # Kh·ªõp v·ªõi lu·ªìng: Resample hourly -> fill missing hours
        df = df.resample('h').ffill() 
        return df['avg_gwei']

    def _train_model(self, data):
        """
        Hu·∫•n luy·ªán m√¥ h√¨nh ARIMA.
        Kh·ªõp v·ªõi lu·ªìng: _train_model() -> ARIMA(1,1,1).fit()
        """
        print("[Pillar 2] ƒêang hu·∫•n luy·ªán m√¥ h√¨nh ARIMA...")
        warnings.filterwarnings("ignore") # T·∫Øt c·∫£nh b√°o statsmodels
        
        # S∆° ƒë·ªì ch·ªâ ƒë·ªãnh (1,1,1)
        model = ARIMA(data, order=(1, 1, 1))
        self.model_fit = model.fit()
        print("[Pillar 2] Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t.")
        warnings.filterwarnings("default")

    def _calculate_model_accuracy(self, data):
        """
        T√≠nh to√°n ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh ARIMA b·∫±ng c√°ch backtesting.
        
        Ph∆∞∆°ng ph√°p: Walk-forward validation
        - Chia d·ªØ li·ªáu th√†nh train (80%) v√† test (20%)
        - Hu·∫•n luy·ªán tr√™n train, d·ª± b√°o test
        - T√≠nh c√°c metrics: MAE, RMSE, MAPE
        
        Returns:
            dict: C√°c metrics ƒë·ªô ch√≠nh x√°c
        """
        if len(data) < 48:  # C·∫ßn √≠t nh·∫•t 48 gi·ªù (2 ng√†y) ƒë·ªÉ backtesting
            print("[Pillar 2] Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (c·∫ßn >= 48 gi·ªù).")
            return None
        
        # Chia d·ªØ li·ªáu: 80% train, 20% test
        split_idx = int(len(data) * 0.8)
        train_data = data[:split_idx]
        test_data = data[split_idx:]
        
        print(f"[Pillar 2] ƒêang ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c: Train={len(train_data)}h, Test={len(test_data)}h...")
        
        warnings.filterwarnings("ignore")
        try:
            # Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n t·∫≠p train
            model_val = ARIMA(train_data, order=(1, 1, 1))
            model_fit_val = model_val.fit()
            
            # D·ª± b√°o cho t·∫≠p test
            forecast_test = model_fit_val.get_forecast(steps=len(test_data))
            predicted_values = forecast_test.predicted_mean
            actual_values = test_data.values
            
            # Lo·∫°i b·ªè NaN n·∫øu c√≥
            mask = ~(np.isnan(predicted_values) | np.isnan(actual_values))
            if mask.sum() == 0:
                print("[Pillar 2] Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ t√≠nh to√°n ƒë·ªô ch√≠nh x√°c.")
                return None
                
            predicted_clean = predicted_values[mask]
            actual_clean = actual_values[mask]
            
            # T√≠nh c√°c metrics
            mae = np.mean(np.abs(predicted_clean - actual_clean))
            rmse = np.sqrt(np.mean((predicted_clean - actual_clean) ** 2))
            
            # MAPE: Tr√°nh chia cho 0
            non_zero_mask = actual_clean != 0
            if non_zero_mask.sum() > 0:
                mape = np.mean(np.abs((actual_clean[non_zero_mask] - predicted_clean[non_zero_mask]) / actual_clean[non_zero_mask])) * 100
            else:
                mape = np.nan
            
            # T√≠nh R-squared (coefficient of determination)
            ss_res = np.sum((actual_clean - predicted_clean) ** 2)
            ss_tot = np.sum((actual_clean - np.mean(actual_clean)) ** 2)
            r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else np.nan
            
            # Model fit metrics t·ª´ m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
            aic = model_fit_val.aic
            bic = model_fit_val.bic
            log_likelihood = model_fit_val.llf
            
            accuracy_metrics = {
                "mae": mae,
                "rmse": rmse,
                "mape": mape,
                "r_squared": r_squared,
                "aic": aic,
                "bic": bic,
                "log_likelihood": log_likelihood,
                "test_samples": len(test_data)
            }
            
            warnings.filterwarnings("default")
            return accuracy_metrics
            
        except Exception as e:
            print(f"[Pillar 2] L·ªói khi ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c: {e}")
            warnings.filterwarnings("default")
            return None

    def run(self, forecast_days=7, use_cache: bool = False, save_cache: bool = True) -> dict:
        """
        Ch·∫°y ph√¢n t√≠ch Pillar 2 ƒë·∫ßy ƒë·ªß.
        Kh·ªõp v·ªõi lu·ªìng: Forecast -> Compute rolling(4h).mean() -> Find min avg_gwei
        
        Args:
            forecast_days: S·ªë ng√†y d·ª± b√°o (m·∫∑c ƒë·ªãnh: 7)
            use_cache: N·∫øu True, s·∫Ω ƒë·ªçc t·ª´ cache n·∫øu c√≥, kh√¥ng query l·∫°i BigQuery
            save_cache: N·∫øu True, s·∫Ω l∆∞u k·∫øt qu·∫£ v√†o cache sau khi ph√¢n t√≠ch
        """
        # Import DataCache ·ªü ƒë√¢y ƒë·ªÉ tr√°nh circular import
        from analysis.data_cache import DataCache
        
        cache = DataCache()
        
        # Th·ª≠ ƒë·ªçc t·ª´ cache n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        if use_cache:
            cached_result = cache.load_pillar2(forecast_days)
            if cached_result is not None:
                print("[Pillar 2] ƒê√£ s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ cache (kh√¥ng query BigQuery).")
                return cached_result
        
        print("\n--- B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch Pillar 2: Chi ph√≠ Gas ---")
        
        # Th·ª≠ ƒë·ªçc d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ cache tr∆∞·ªõc
        data = None
        if use_cache:
            data = cache.load_pillar2_historical(days_back=30)
        
        # N·∫øu kh√¥ng c√≥ trong cache, query t·ª´ BigQuery
        if data is None:
            data = self._fetch_hourly_gas(days_back=30)
            # L∆∞u d·ªØ li·ªáu l·ªãch s·ª≠ v√†o cache
            if save_cache and data is not None:
                cache.save_pillar2_historical(data, days_back=30)
        
        if data is None:
            return {"error": "Kh√¥ng c√≥ d·ªØ li·ªáu gas"}
            
        self._train_model(data)
        
        # T√≠nh to√°n ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh (backtesting)
        accuracy_metrics = self._calculate_model_accuracy(data)
        
        # In ra c√°c metrics ƒë·ªô ch√≠nh x√°c
        if accuracy_metrics:
            print("\n=== ƒê·ªò CH√çNH X√ÅC M√î H√åNH ARIMA (Backtesting) ===")
            print(f"  ‚Ä¢ MAE (Mean Absolute Error): {accuracy_metrics['mae']:.4f} Gwei")
            print(f"  ‚Ä¢ RMSE (Root Mean Squared Error): {accuracy_metrics['rmse']:.4f} Gwei")
            if not np.isnan(accuracy_metrics['mape']):
                print(f"  ‚Ä¢ MAPE (Mean Absolute Percentage Error): {accuracy_metrics['mape']:.2f}%")
            if not np.isnan(accuracy_metrics['r_squared']):
                print(f"  ‚Ä¢ R¬≤ (Coefficient of Determination): {accuracy_metrics['r_squared']:.4f}")
                print(f"    ‚Üí Gi·∫£i th√≠ch: {accuracy_metrics['r_squared']*100:.2f}% ph∆∞∆°ng sai ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi m√¥ h√¨nh")
            print(f"  ‚Ä¢ AIC (Akaike Information Criterion): {accuracy_metrics['aic']:.2f}")
            print(f"  ‚Ä¢ BIC (Bayesian Information Criterion): {accuracy_metrics['bic']:.2f}")
            print(f"  ‚Ä¢ Log Likelihood: {accuracy_metrics['log_likelihood']:.2f}")
            print(f"  ‚Ä¢ S·ªë m·∫´u test: {accuracy_metrics['test_samples']} gi·ªù")
            
            # ƒê√°nh gi√° ƒë·ªô tin c·∫≠y d·ª±a tr√™n MAPE
            mape = accuracy_metrics.get('mape', np.nan)
            if not np.isnan(mape):
                if mape < 5:
                    reliability = "R·∫§T CAO"
                elif mape < 10:
                    reliability = "CAO"
                elif mape < 20:
                    reliability = "TRUNG B√åNH"
                else:
                    reliability = "TH·∫§P"
                print(f"\n  üìä ƒê·ªò TIN C·∫¨Y D·ª∞ B√ÅO: {reliability} (MAPE = {mape:.2f}%)")
            
            print("=" * 50)
        else:
            print("[Pillar 2] Kh√¥ng th·ªÉ ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (thi·∫øu d·ªØ li·ªáu ho·∫∑c l·ªói).")
        
        # L·∫•y c√°c metrics t·ª´ m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (full data)
        if self.model_fit is not None:
            full_model_metrics = {
                "aic_full": self.model_fit.aic,
                "bic_full": self.model_fit.bic,
                "log_likelihood_full": self.model_fit.llf
            }
        else:
            full_model_metrics = {}
        
        steps_to_forecast = forecast_days * 24 # 7 ng√†y * 24 gi·ªù
        print(f"\n[Pillar 2] ƒêang d·ª± b√°o cho {steps_to_forecast} gi·ªù t·ªõi...")
        forecast = self.model_fit.get_forecast(steps=steps_to_forecast)
        forecast_df = forecast.conf_int(alpha=0.05)
        forecast_df['predicted_gwei'] = forecast.predicted_mean
        
        # Kh·ªõp v·ªõi lu·ªìng: Compute rolling(4h).mean()
        window_size_hours = 4
        rolling_avg = forecast_df['predicted_gwei'].rolling(window=window_size_hours).mean()
        
        # Kh·ªõp v·ªõi lu·ªìng: Find min avg_gwei -> best_window_start
        best_window_start = rolling_avg.idxmin()
        if pd.isna(best_window_start):
             best_window_start = forecast_df['predicted_gwei'].idxmin()
             
        best_gas = rolling_avg.min()
        
        print(f"[Pillar 2] Ho√†n t·∫•t. C·ª≠a s·ªï 4 gi·ªù r·∫ª nh·∫•t b·∫Øt ƒë·∫ßu l√∫c: {best_window_start} UTC")
        
        result = {
            "best_window_start_utc": str(best_window_start),
            "estimated_avg_gwei": best_gas,
            "forecast_dataframe": forecast_df
        }
        
        # Th√™m accuracy metrics v√†o k·∫øt qu·∫£
        if accuracy_metrics:
            result["model_accuracy"] = accuracy_metrics
        
        if full_model_metrics:
            result["model_fit_metrics"] = full_model_metrics
        
        # L∆∞u v√†o cache n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        if save_cache:
            cache.save_pillar2(result, forecast_days)
        
        return result